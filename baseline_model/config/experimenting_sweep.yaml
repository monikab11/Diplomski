program: train.py
name: training_batches # pooling_functions
method: grid  # Bayesian works for small number of continuous parameters.
metric:
  goal: minimize
  name: test_loss
parameters:
  architecture:
    value: GraphSAGE
  hidden_channels:
    values: [64, 16, 32]
  gnn_layers:
    values: [4, 3, 5]
  mlp_layers:
    value: 2
  dropout:
    value: 0.0
  activation:
    value: relu
  pool:
    value: multi
  optimizer:
    value: adam
  learning_rate:
    values: [0.001, 0.01]
  epochs:
    values: [20, 100]
  jk:
    values: ["none"] # ["none"] # "cat"
  features:
    values: [["degree"], ["degree", "clustering"], ["degree", "clustering", "pagerank", "betweenness", "eigenvector"]]
  edge_feature_mode:
    value: "dot"
  loss_fn:
    values: ["mse", "combined", "ranking"]
  feature_normalization:
    values: [False, True]


command:
  - ${env}
  - ${interpreter}
  - ${program}


